{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klyO5c7yjr9Q"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.utils import to_categorical\n",
        "from keras import metrics\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout,Maximum\n",
        "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose,Conv3D,Conv3DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D,MaxPooling3D\n",
        "from keras.layers.merge import concatenate, add\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "from skimage.io import imread, imshow, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import CSVLogger\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "import os\n",
        "from skimage.io import imread, imshow, concatenate_images\n",
        "from skimage.transform import resize\n",
        "# from medpy.io import load\n",
        "import numpy as np\n",
        "\n",
        "#import cv2\n",
        "import nibabel as nib\n",
        "from PIL import Image\n",
        "\n",
        "def conv_block(input_mat,num_filters,kernel_size,batch_norm):\n",
        "  X = Conv2D(num_filters,kernel_size=(kernel_size,kernel_size),strides=(1,1),padding='same')(input_mat)\n",
        "  if batch_norm:\n",
        "    X = BatchNormalization()(X)\n",
        "  \n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  X = Conv2D(num_filters,kernel_size=(kernel_size,kernel_size),strides=(1,1),padding='same')(X)\n",
        "  if batch_norm:\n",
        "    X = BatchNormalization()(X)\n",
        "  \n",
        "  X = Activation('relu')(X)\n",
        "  \n",
        "  return X\n",
        "\n",
        "def Unet_with_slice(input_img, n_filters = 32 , dropout = 0.14 , batch_norm = True):\n",
        "  c1 = Conv2D(16,kernel_size = (1,6) , strides = (1,1) ,padding = 'valid')(input_img)\n",
        "  if batch_norm:\n",
        "    c1 = BatchNormalization()(c1)\n",
        "  #print(c1.shape)\n",
        "  c1 = Activation('relu')(c1)\n",
        "\n",
        "  c1 = Conv2D(n_filters,kernel_size=(3,3),strides=(1,1),padding='same')(c1)\n",
        "  if batch_norm:\n",
        "    c1 = BatchNormalization()(c1)\n",
        "  \n",
        "  c1 = Activation('relu')(c1)\n",
        "\n",
        "  p1 = MaxPooling2D(pool_size = (2,2) , strides = 2)(c1)\n",
        "  p1 = Dropout(dropout)(p1)\n",
        "\n",
        "  #print(p1.shape)\n",
        "  c2 = conv_block(p1 , n_filters*2,3,batch_norm)\n",
        "  p2 = MaxPooling2D(pool_size=(3,3), strides=3)(c2)\n",
        "  p2 = Dropout(dropout)(p2)\n",
        "  #print(p2.shape)\n",
        "\n",
        "  c3 = conv_block(p2, n_filters*4,3,batch_norm)\n",
        "  #print(c3.shape)\n",
        "  p3 = MaxPooling2D(pool_size = (2,1) , strides = (2,1))(c3)\n",
        "  p3 = Dropout(dropout)(p3)\n",
        "  #print(p3.shape)\n",
        "\n",
        "  c4 = conv_block(p3, n_filters*8,3,batch_norm)\n",
        "  p4 = MaxPooling2D(pool_size = (4,4) , strides = (4,5))(c4)\n",
        "  p4 = Dropout(dropout)(p4)\n",
        "\n",
        "  c5 = conv_block(p4,n_filters*16,3,batch_norm)\n",
        "\n",
        "  u6 = Conv2DTranspose(n_filters*8,kernel_size = (4,4) , strides = (4,5) , padding = 'same')(c5)\n",
        "  u6 = concatenate([u6,c4])\n",
        "  c6 = conv_block(u6,n_filters*8,3,batch_norm)\n",
        "  c6 = Dropout(dropout)(c6)\n",
        "\n",
        "  u7 = Conv2DTranspose(n_filters*4,kernel_size = (3,3) , strides = (2,1) , padding = 'same')(c6)\n",
        "  u7 = concatenate([u7,c3])\n",
        "  c7 = conv_block(u7,n_filters*4,3,batch_norm)\n",
        "  c7 = Dropout(dropout)(c7)\n",
        "\n",
        "  u8 = Conv2DTranspose(n_filters*2,kernel_size = (3,3) , strides = (3,3) , padding = 'same')(c7)\n",
        "  u8 = concatenate([u8,c2])\n",
        "  c8 = conv_block(u8,n_filters*2,3,batch_norm)\n",
        "  c8 = Dropout(dropout)(c8)\n",
        "\n",
        "  u9 = Conv2DTranspose(n_filters,kernel_size = (3,3) , strides = (2,2) , padding = 'same')(c8)\n",
        "  u9 = concatenate([u9,c1])\n",
        "  c9 = conv_block(u9,n_filters,3,batch_norm)\n",
        "  c9 = Dropout(dropout)(c9)\n",
        "\n",
        "  c10 = Conv2DTranspose(n_filters, kernel_size = (1,6) , strides = (1,1), padding = 'valid')(c9)\n",
        "\n",
        "  outputs = Conv2D(2, kernel_size = (1,1), activation = 'softmax')(c10)\n",
        "\n",
        "  model = Model(inputs = input_img , outputs = outputs)\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def standardize(image):\n",
        "\n",
        "  standardized_image = np.zeros(image.shape)\n",
        "\n",
        "  #\n",
        "  \n",
        "      # iterate over the `z` dimension\n",
        "  for z in range(image.shape[2]):\n",
        "      # get a slice of the image \n",
        "      # at channel c and z-th dimension `z`\n",
        "      image_slice = image[:,:,z]\n",
        "\n",
        "      # subtract the mean from image_slice\n",
        "      centered = image_slice - np.mean(image_slice)\n",
        "      \n",
        "      # divide by the standard deviation (only if it is different from zero)\n",
        "      if(np.std(centered)!=0):\n",
        "          centered = centered/np.std(centered) \n",
        "\n",
        "      # update  the slice of standardized image\n",
        "      # with the scaled centered and scaled image\n",
        "      standardized_image[:, :, z] = centered\n",
        "\n",
        "  ### END CODE HERE ###\n",
        "\n",
        "  return standardized_image\n",
        "\n",
        "\n",
        "def dice_coef(y_true, y_pred, epsilon=0.00001):\n",
        "    \"\"\"\n",
        "    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
        "         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
        "    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n",
        "    \n",
        "    \"\"\"\n",
        "    axis = (0,1,2)\n",
        "    dice_numerator = 2. * K.sum(y_true * y_pred, axis=axis) + epsilon\n",
        "    dice_denominator = K.sum(y_true*y_true, axis=axis) + K.sum(y_pred*y_pred, axis=axis) + epsilon\n",
        "    return K.mean((dice_numerator)/(dice_denominator))\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1-dice_coef(y_true, y_pred)\n",
        "\n",
        "\n",
        "input_img = Input((240,155,4))\n",
        "model = Unet_with_slice(input_img,32,0.14,True)\n",
        "learning_rate = 0.00095\n",
        "#epochs = 5000\n",
        "decay_rate = 0.0000002\n",
        "model.compile(optimizer=Adam(lr=learning_rate, decay = decay_rate), loss=dice_coef_loss, metrics=[dice_coef])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "path = '/content/drive/MyDrive/BRATS2018TRAIN/HGG'\n",
        "all_images = os.listdir(path)\n",
        "#print(len(all_images))\n",
        "all_images.sort()\n",
        "data = np.zeros((240,240,155,4))\n",
        "image_data2=np.zeros((240,240,155))\n",
        "loss_hist = []\n",
        "accu_hist = []\n",
        "epoch_wise_loss = []\n",
        "epoch_wise_accu = []\n",
        "for epochs in range(5):\n",
        "  epoch_loss = 0\n",
        "  epoch_accu = 0\n",
        "  for image_num in range(180):\n",
        "    x_to = []\n",
        "    y_to = []\n",
        "    print(epochs)\n",
        "    print(image_num)\n",
        "\n",
        "# data preprocessing starts here\n",
        "\n",
        "    x = all_images[image_num]\n",
        "    print(x)\n",
        "    folder_path = path + '/' + x;\n",
        "    modalities = os.listdir(folder_path)\n",
        "    modalities.sort()\n",
        "    #data = []\n",
        "    w = 0\n",
        "    for j in range(len(modalities)):\n",
        "      #print(modalities[j])\n",
        "      \n",
        "      image_path = folder_path + '/' + modalities[j]\n",
        "      if not(image_path.find('seg.nii') == -1):\n",
        "        img = nib.load(image_path);\n",
        "        image_data2 = img.get_data()\n",
        "        image_data2 = np.asarray(image_data2)\n",
        "        print(\"Entered ground truth\")\n",
        "      else:\n",
        "        img = nib.load(image_path);\n",
        "        image_data = img.get_data()\n",
        "        image_data = np.asarray(image_data)\n",
        "        image_data = standardize(image_data)\n",
        "        data[:,:,:,w] = image_data\n",
        "        print(\"Entered modality\")\n",
        "        w = w+1\n",
        "      \n",
        "    print(data.shape)\n",
        "    print(image_data2.shape)  \n",
        "    \n",
        "    '''\n",
        "    reshaped_data=data[56:184,75:203,13:141,:]\n",
        "    reshaped_data=reshaped_data.reshape(1,128,128,128,4)\n",
        "    reshaped_image_data2=image_data2[56:184,75:203,13:141]\n",
        "\n",
        "        \n",
        "    reshaped_image_data2=reshaped_image_data2.reshape(1,128,128,128)\n",
        "    reshaped_image_data2[reshaped_image_data2==4] = 3\n",
        "    hello = reshaped_image_data2.flatten()\n",
        "    #y_to = keras.utils.to_categorical(y_to,num_classes=2)\n",
        "    print(reshaped_image_data2.shape)\n",
        "    #print(hello[hello==3].shape)\n",
        "    print(\"Number of classes\",np.unique(hello))\n",
        "    class_weights = class_weight.compute_class_weight('balanced',np.unique(hello),hello)\n",
        "    print(class_weights)\n",
        "    \n",
        "    \n",
        "    '''\n",
        "    \n",
        "    \n",
        "    for slice_no in range(0,240):\n",
        "        a = slice_no\n",
        "        X = data[slice_no,:,:,:]\n",
        "\n",
        "        Y = image_data2[slice_no,:,:]\n",
        "        # imgplot = plt.imshow(X[:,:,2])\n",
        "        # plt.show(block=False)\n",
        "        # plt.pause(0.3)\n",
        "        # plt.close()\n",
        "\n",
        "        # imgplot = plt.imshow(Y)\n",
        "        # plt.show(block=False)\n",
        "        # plt.pause(0.3)\n",
        "        # plt.close()\n",
        "\n",
        "        if(X.any()!=0 and Y.any()!=0 and len(np.unique(Y)) == 4):\n",
        "          #print(slice_no)\n",
        "          x_to.append(X)\n",
        "          y_to.append(Y)\n",
        "          if len(y_to)>=63:\n",
        "                break;\n",
        "\n",
        "        #reshaped_image_data2 = to_categorical(reshaped_image_data2, num_classes = 4)\n",
        "\n",
        "        #print(reshaped_data.shape)\n",
        "        #print(reshaped_image_data2.shape)\n",
        "        #print(type(reshaped_data))\n",
        "\n",
        "    x_to = np.asarray(x_to)\n",
        "    y_to = np.asarray(y_to)\n",
        "    print(x_to.shape)\n",
        "    print(y_to.shape)\n",
        "\n",
        "  \n",
        "    y_to[y_to==4] = 1         \n",
        "    #y_to = one_hot_encode(y_to)\n",
        "    y_to[y_to==2] = 1\n",
        "    y_to[y_to==1] = 1\n",
        "    y_to[y_to==0] = 0\n",
        "    print(y_to.shape)\n",
        "    \n",
        "    \n",
        "    from sklearn.utils import shuffle\n",
        "    x_to,y_to = shuffle(x_to,y_to)\n",
        "    \n",
        "    hello = y_to.flatten()\n",
        "    #print(hello[hello==3].shape)\n",
        "    print(\"Number of classes\",np.unique(hello))\n",
        "    class_weights = class_weight.compute_class_weight('balanced',np.unique(hello),hello)\n",
        "  \n",
        "    #class_weights.insert(3,0)\n",
        "    print(\"class_weights\",class_weights)\n",
        "\n",
        "\n",
        "    y_to = keras.utils.to_categorical(y_to,num_classes=2)\n",
        "    history = model.fit(x=x_to,y=y_to, epochs = 1 , batch_size = 63 )\n",
        "    print(history.history['loss'])\n",
        "    epoch_loss += history.history['loss'][0]\n",
        "    epoch_accu += history.history['dice_coef'][0]\n",
        "    \n",
        "    loss_hist.append(history.history['loss'])\n",
        "    accu_hist.append(history.history['dice_coef'])\n",
        "  \n",
        "  model.save('/content/drive/MyDrive/models/2dclasses2_model_axis1.h5')\n",
        "  epoch_loss = epoch_loss/180\n",
        "  epoch_accu = epoch_accu/180\n",
        "\n",
        "  epoch_wise_loss.append(epoch_loss)\n",
        "  epoch_wise_accu.append(epoch_accu)\n",
        "  \n",
        "  plt.plot(epoch_wise_loss)\n",
        "  plt.title('Model_loss vs epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('epochs')\n",
        "  s = '/content/drive/MyDrive/SAVEFIG/epochwise_loss_2dclasses2axis1s' + str(epochs)\n",
        "  plt.savefig(s)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "  \n",
        "  plt.plot(epoch_wise_accu)\n",
        "  plt.title('Model_Accuracy vs epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('epochs')\n",
        "  s = '/content/drive/MyDrive/SAVEFIG/epochwise_accu_2dclasses2axis1s' + str(epochs)\n",
        "  plt.savefig(s)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "    \n",
        "  plt.plot(accu_hist)\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  s = '/content/drive/MyDrive/SAVEFIG/accuracy_plot_2dclasses2axis1s' + str(epochs)\n",
        "  plt.savefig(s)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "    \n",
        "  plt.plot(loss_hist)\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  s = '/content/drive/MyDrive/SAVEFIG/loss_plot_2dclasses2axis1s' + str(epochs)\n",
        "  plt.savefig(s)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "model.save('/content/drive/MyDrive/models/2dclasses2_model_axis1.h5')\n",
        "\n"
      ]
    }
  ]
}